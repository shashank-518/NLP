{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6fae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eaten\",\"finally\",\"finalized\",\"programming\",\"programed\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc1eb94",
   "metadata": {},
   "source": [
    "###PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8db306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "311f3266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------> Stem word = eat\n",
      "eaten------> Stem word = eaten\n",
      "finally------> Stem word = final\n",
      "finalized------> Stem word = final\n",
      "programming------> Stem word = program\n",
      "programed------> Stem word = program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\"------> Stem word = \"+ stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c234fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "reg_exp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "\n",
    "reg_exp.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7479bcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eaten------>eaten\n",
      "finally------>final\n",
      "finalized------>final\n",
      "programming------>program\n",
      "programed------>program\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snow = SnowballStemmer('english')\n",
    "\n",
    "for word in words:\n",
    "    print(word + \"------>\"+ snow.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2e417c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fair'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem('fairly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee2db8",
   "metadata": {},
   "source": [
    "### LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e21077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f8ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff0f47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\shash\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec6006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('going', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d87fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eaten------>eat\n",
      "finally------>finally\n",
      "finalized------>finalize\n",
      "programming------>program\n",
      "programed------>program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"------>\"+ lemmatizer.lemmatize(word, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be873b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaskenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
